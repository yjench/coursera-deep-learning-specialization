# Deep Learning Specialization

This repo contains my coursework for [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) taughted by Andrew Ng et al., deeplearning.ai, on the Coursera platform. The specialization requires a time investment of about 80 hours.

This specialization covers a broad range of topics of deep learning by using a hands-on approach: it explains the basic concepts, gives intuition on why they work, and let learners practice what they learn through a series of programming assignments.

The assignments use Python and the Jupyter Notebook environment. For grading purposes, most of the programs is written in the functional programming style. In the first half of the assignments, neural networks are coded up from scratch using NumPy. In the second half of the assignments, Keras and TensorFlow (version 1) are used to tackle more complex NN architectures. Other packages used include SciPy, Matplotlib, PIL and h5py.



**⚠️ Note on honor code**

While I try to keep this repo as low-profile as possible, it has been made temporarily public. If you are a currently enrolled student of the course and accidentally stumble into this repo, please take a look at the [Coursera Honor Code](https://learner.coursera.help/hc/en-us/articles/209818863-Coursera-Honor-Code): please use the contents of this repo only as a reference and don't copy any code.



## Contents

The specialization is divided into 5 courses, each of which contains 2 - 4 modules. The folder for each module (M) includes my solutions for the quiz and programming assignment(s) (PA).

### Course 1. Neural Networks and Deep Learning

This course covers standard fully connected, feedforward neural networks, with a focus on binary classification applications. NumPy and vectorization are also introduced.

* [**M1. Introduction to deep learning**](https://github.com/yjench/coursera-deep-learning-specialization/tree/master/C1M1%20-%20Introduction%20to%20deep%20learning)
* [**M2. Basics of neural network programming**](https://github.com/yjench/coursera-deep-learning-specialization/tree/master/C1M2%20-%20Basics%20of%20neural%20network%20programming)
  * [PA1. Python basics with Numpy](https://github.com/yjench/coursera-deep-learning-specialization/blob/master/C1M2%20-%20Basics%20of%20neural%20network%20programming/Python%20basics%20with%20Numpy/Python_Basics_With_Numpy_v3a.ipynb)
  * [PA2. Logistic regression as a neural network](https://github.com/yjench/coursera-deep-learning-specialization/blob/master/C1M2%20-%20Basics%20of%20neural%20network%20programming/Logistic%20regression%20as%20a%20neural%20network/Logistic_Regression_with_a_Neural_Network_mindset_v6a.ipynb)
* [**M3. Shallow neural networks**](https://github.com/yjench/coursera-deep-learning-specialization/tree/master/C1M3%20-%20Shallow%20neural%20networks)
  * [PA1. Planar data classification with one hidden layer](https://github.com/yjench/coursera-deep-learning-specialization/blob/master/C1M3%20-%20Shallow%20neural%20networks/Planar%20data%20classification%20with%20one%20hidden%20layer/Planar_data_classification_with_onehidden_layer_v6c.ipynb)
* [**M4. Deep neural networks**](https://github.com/yjench/coursera-deep-learning-specialization/tree/master/C1M4%20-%20Deep%20neural%20networks)
  * [PA1. Building your deep neural network - step by step](https://github.com/yjench/coursera-deep-learning-specialization/blob/master/C1M4%20-%20Deep%20neural%20networks/Building%20your%20deep%20neural%20network%20-%20step%20by%20step/Building_your_Deep_Neural_Network_Step_by_Step_v8a.ipynb)
  * [PA2. Deep neural network application](https://github.com/yjench/coursera-deep-learning-specialization/blob/master/C1M4%20-%20Deep%20neural%20networks/Deep%20neural%20network%20application/Deep%2BNeural%2BNetwork%2B-%2BApplication%2Bv8.ipynb)



**Course 2. Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization**

This course covers techniques and practical tips to train deep neural networks, and diagonose bias/variance problems, and improve performance.

 regularization, vriances of batch gradient descent, 

